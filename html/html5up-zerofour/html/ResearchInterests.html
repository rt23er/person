<!DOCTYPE HTML>
<!--
	ZeroFour by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
    <title>Main Course</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="../assets/css/main.css"/>
    <link rel="stylesheet" href="../css/Research.css">

    <script src="../js/vue.js">

    </script>
</head>
<body class="homepage is-preload">


<div id="app">
    <div id="page-wrapper">

        <!-- Header -->
        <div id="header-wrapper">
            <div class="container">

                <!-- Header -->
                <header id="header">
                    <div class="inner">

                        <!-- Logo -->
                        <h1><a href="../index.html" id="logo">PERSONAL SITE</a></h1>

                        <!-- Nav -->
                        <nav id="nav">
                            <ul>
                                <li class="current_page_item"><a href="../index.html">Home</a></li>
                                <li>
                                    <a href="#">Education</a>
                                    <ul>
                                        <li><a href="./EducationalBackground.html">Educational Background</a></li>
                                        <li><a href="./MainCourse.html">Main Course</a></li>
                                    </ul>
                                </li>
                                <li><a href="#">Work</a>
                                    <ul>
                                        <li><a href="./Internship.html">Internship</a></li>
                                        <li><a href="./FullTimeJob.html">Full-time Job</a></li>
                                    </ul>

                                </li>
                                <li><a href="#">Research</a>
                                    <ul>
                                        <li><a href="./ResearchInterests.html">Research Interests</a></li>
                                        <li><a href="./PaperCollection.html">Paper Collection</a></li>
                                        <li><a href="./PaperReviews.html">Paper Reviews</a></li>
                                    </ul>
                                </li>
                                <li><a href="./Publication.html">Publication</a></li>
                                <li><a href="./Blog.html">Blog</a></li>
                                <li><a href="./Life.html">Life</a></li>
                            </ul>
                        </nav>

                    </div>
                </header>

                <!-- Banner -->

                <!--      时间线-->
                <div class="container2">

                    <div class="content">
                        <h2>
                            Introduction
                        </h2>
                        <p>
                            The objective of my research is to develop a recommendation system (RS) driven by Large
                            Language Models (LLMs) to provide more personalized and human-centric services across
                            various downstream applications such as music recommendation, product recommendation, app
                            recommendation, and movie recommendation. Conventional Recommendation Models (CRMs) face
                            significant limitations, including a lack of open-domain world knowledge and insufficient
                            explainability of recommendations.
                        </p>
                        <p>
                            The emergence of large foundation models, particularly LLMs, offers promising and universal
                            insights for addressing challenging problems in the data mining field. These models
                            demonstrate impressive general intelligence across various language processing tasks due to
                            their extensive memory of open-world knowledge, logical and commonsense reasoning
                            capabilities, and awareness of human society and culture. By leveraging natural language as
                            a universal information carrier, LLMs can integrate, exploit, and interpret knowledge across
                            different forms, modalities, domains, and platforms.[1]
                        </p>
                        <p>
                            My research interest aims to explore the incorporation of LLMs into recommender systems to
                            overcome the inherent drawbacks of CRMs by utilizing LLMs' common knowledge and reasoning
                            abilities. The goal is to enhance the performance and user experience of recommendation
                            systems, making them more intelligent, explainable, and effective in understanding and
                            catering to user needs across various application domains.
                        </p>

                        <h2>
                            Literature Review
                        </h2>
                        <p>
                            Recently, RS researchers and practitioners have made pioneering attempts to employ Large
                            Language Models (LLMs) in current recommendation pipelines, achieving notable progress in
                            enhancing the performance of various canonical recommendation processes such as feature
                            modeling and ranking. Several survey works delve into the potential of LLMs for general
                            recommender systems:
                        </p>
                        <li>
                            Wu et al. [2] conduct a review on both discriminative and generative LLMs for
                            recommendation with different tuning strategies.
                        </li>
                        <li>
                            Fan et al. [3] focus on the pretraining, finetuning and prompting approaches when
                            leveraging LLM for recommendation.
                        </li>
                        <li>
                            Huang et al. [4] investigate the recommendation foundation models from aspects of both
                            different model types and various downstream tasks.
                        </li>

                        <p>
                            According to the research of previous scholars and the current state-of-the-art [1,5], there
                            are three primary approaches for LLM-driven recommendation systems:
                        </p>
                        <li>
                            Sequential Integration of LLM and RS (Serial Approach)【串联】
                        </li>
                        <li>
                            2.LLM as a Replacement for Traditional RS Architecture (LLM as RS)
                        </li>
                        <li>
                            3.Fusion of LLM and RS (Fusion Approach)【融合】
                        </li>
                        <img src="../Resource/Research/ri1.png" alt="">
                        <h2>
                            Approach 1: Sequential Integration of LLM and RS
                        </h2>
                        <p>
                            This approach involves using LLMs to process upstream data before inputting it into the
                            recommendation system for final ranking and decision-making. There are two main paradigms:
                        </p>

                        <li>
                            <strong>LLM Embeddings + RS:</strong> LLM generates embeddings for items and users, which
                            are then input into the recommendation system. E.g., Xiaohongshu's "NoteLLM: A Retrievable
                            Large Language Model for Note Recommendation" [6]
                        </li>

                        <li>
                            <strong>LLM Tokens + RS:</strong> LLM processes raw text data from users and items directly
                            and then passes the processed results to the recommendation system. E.g., Huawei's "CTRL:
                            Connect Collaborative and Language Model for CTR Prediction" [7]
                        </li>
                        <h2>
                            Approach 2: LLM as RS
                        </h2>

                        <p>
                            In this approach, LLMs are used directly as recommendation systems. This method leverages
                            the generative capabilities of LLMs by constructing detailed prompts and instructions,
                            enabling the LLM to generate recommendations based on user and item information. E.g.,
                            Meta's "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for
                            Generative Recommendations" [8]
                        </p>

                        <div class="flex">
                            <div class="img">
                                <img src="../Resource/Research/ri2.png" alt="">
                            </div>

                            <div class="img">
                                <img src="../Resource/Research/ri3.png" alt="">
                            </div>
                        </div>
                        <h2>
                            Approach 3: Fusion of LLM and RS
                        </h2>
                        <p>
                            This approach addresses both the "WHERE" and "HOW" questions of integrating LLMs into RS:
                        </p>
                        <li>
                            <strong>WHERE: </strong>
                            Discusses the roles that LLMs could play at different stages of the recommendation system
                            pipeline, from data collection to the recommendation pipeline controller. The modern deep
                            learning-based recommender systems can be characterized as an information cycle encompassing
                            six key stages:
                        </li>

                        <li>
                            1.Data Collection: Gathering user feedback data.
                        </li>
                        <li>
                            2.Feature Engineering: Preparing and processing the collected raw data.
                        </li>

                        <li>3.Feature Encoder: Transforming data features into neural embeddings.</li>
                        <li>4.Scoring/Ranking Function: Selecting and ordering the recommended items.</li>
                        <li>5.User Interaction: Determining how users engage with the recommendations.</li>
                        <li>6.Recommendation Pipeline Controller: Serving as the central mechanism tying all the stages
                            together in a cohesive process.
                        </li>
                        <p>
                            <strong>
                                HOW:
                            </strong> Centers on how to adapt LLMs for RS, with two orthogonal taxonomy criteria:
                        </p>

                        <li>1.Parameter Freezing: Whether to freeze the parameters of the LLM during the training
                            phase.
                        </li>
                        <li>2.Involvement of CRM: Whether to involve conventional recommendation models (CRM) during the
                            inference phase.
                        </li>
                        <h2>
                            Research Plan
                        </h2>
                        <img src="../Resource/Research/rp.png" alt="">
                        <h3>1.Comparison of LLM+RS Research Paradigms</h3>
                        <li>Conduct a comparative analysis of the three mainstream LLM+RS research approaches:
                            sequential integration, LLM as RS, and fusion of LLM and RS.
                        </li>
                        <li>Perform experimental comparisons to evaluate the strengths and limitations of each
                            approach.
                        </li>
                        <li>Establish effective evaluation criteria to assess the performance and suitability of these
                            approaches.
                        </li>
                        <h3>2.Exploring Solutions to Current RS Drawbacks with LLM Integration</h3>
                        <p>
                            Investigate whether the integration of LLMs can address the current limitations of
                            recommendation systems, such as:
                        </p>
                        <li>How can LLMs help solve the cold start problem and improve recommendation performance for
                            new users or new content?
                        </li>

                        <li>Can LLMs help mitigate the information cocoons effect and expand user interests?</li>

                        <li>How can LLMs facilitate the effective recommendation of non-popular, long-tail content?
                        </li>

                        <li>In what ways can LLMs enhance the understanding of complex user intentions and contexts?
                        </li>

                        <li>How can LLM-driven recommendation systems provide more explainable recommendations to
                            users?
                        </li>

                        <h3>Downstream Applications of LLM+RS Systems</h3>



                        <li>Explore how LLM+RS systems can influence product diversity sales and the long-tail effect.</li>
                        <li>Investigate the potential of LLM+RS systems to facilitate cross-business and cross-company recommendations.</li>
                        <li>Study how LLM+RS systems can integrate data from different business lines to provide a more comprehensive user profile.</li>
                        <li>Utilize LLMs to deeply understand user behavior and decision-making processes in recommendation systems.</li>
                        <li>Ensure that LLM-driven recommendation systems adhere to ethical standards and promote fairness:</li>
                        <li>How can LLM+RS systems balance personalization and social diversity in recommendations?</li>
                        <li>Can LLMs help reduce biases related to gender, race, and other factors in recommendation systems?</li>
                        <li>Explore the feasibility of LLM+RS systems for recommendations across platforms, regions, fields, and languages.</li>
                        <h1></h1     >

                        <p>
                            [1] <a href="https://arxiv.org/pdf/2306.05817">https://arxiv.org/pdf/2306.05817</a> <br>
                            [2] Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2023. A Survey on Large Language Models for Recommendation. arXiv preprint arXiv:2305.19860 (2023).
                            <br>
                            [3] Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Zhen Wen, Fei Wang, Xiangyu Zhao, Jiliang Tang, and Qing Li. 2023. Recommender Systems in the Era of Large Language Models (LLMs). arXiv:2307.02046 [cs.IR]
                            <br>
                            [4] Chengkai Huang, Tong Yu, Kaige Xie, Shuai Zhang, Lina Yao, and Julian McAuley. 2024. Foundation Models for Recommender Systems: A Survey and New Perspectives. arXiv preprint arXiv:2402.11143 (2024).
                            <br>
                            [5] <a href="https://arxiv.org/pdf/2305.19860">https://arxiv.org/pdf/2305.19860</a> <br>
                            [6] <a href="https://arxiv.org/pdf/2403.01744">https://arxiv.org/pdf/2403.01744</a> <br>
                            [7] <a href="https://arxiv.org/pdf/2306.02841">https://arxiv.org/pdf/2306.02841</a> <br>
                            [8] <a href="https://arxiv.org/abs/2402.17152">https://arxiv.org/abs/2402.17152</a> <br>
                        </p>

                    </div>


                </div>

            </div>

        </div>

    </div>
</div>

<script>
    var app = new Vue({
        el: '#app',
        data: {
            msg: 'Hello Vue!',
            courseDetail: {},
            courselist: [
                {
                    title: 'BA810-Machine Learning for Business Analytics',
                    img: '../images/book1.png',
                    des: "This course will teach students how to perform hands-on analytics on such datasets using modern\n" +
                        "machine learning techniques through series a lectures and in- class team exercises. Students will\n" +
                        "analyze data using the R programming language, derive actionable insights from the data, and\n" +
                        "present their findings. The goal of the course is to create an understanding of modern analytics\n" +
                        "methods, and the types of problems they can be applied to. The course is open to students with\n" +
                        "or without a technical background who are interested in analytics. While no prior programming\n" +
                        "experience is required, students will learn the fundamentals of the R programming language to build\n" +
                        "and evaluate predictive models."
                },
                {
                    title: "BA865-Advanced Analytics I (Introduction to Neural Networks in Python)",
                    img: '../images/book2.png',
                    des: "This course will introduce you to neural networks using the Python programming language in Keras. \n" +
                        "The course will focus on the theory of Neural Networks and Deep Learning concepts and \n" +
                        "implementation in Keras. The material will be presented through a combination of lecture slides \n" +
                        "interactive python notebooks (Google Colab)"
                }
                , {
                    title: "BA870-Topics in Financial and Accounting Analytics",
                    img: '../images/book3.png',
                    des: " The primary objective of this course is to introduce Questrom MSBA\n" +
                        "students to key financial and accounting (F&A) concepts, data sources and data \n" +
                        "analytics tools to solve real and important F&A problems. The course builds on Questrom\n" +
                        "MSBA students’ prior statistical, data science and programming courses for F&A \n" +
                        "applications and problems. In addition, we introduce new complementary tools and data \n" +
                        "sources to students’ analytics toolkit using Python applications and databases (including \n" +
                        "BERT, ScikitLearn, Google Colab, WRDS, Yahoo Finance, and SEC_Edgar). The course \n" +
                        "is designed for business-focused data scientists/analysts who will have to identify, gather, \n" +
                        "parse, analyze and present F&A data to understand, solve and communicate solutions\n" +
                        "for real business problems. The course is designed to be “hands on” and involves many \n" +
                        "example applications and cases."
                },
                {
                    title: "BA885-Advanced Analytics II",
                    img: '../images/book4.png',
                    des: "This course will build on BA865 by going deeper into various aspects of Neural Networks and Deep\n" +
                        "Learning. Our programming language of choice will be Python and we will primarily use TensorFlow/Keras\n" +
                        "for implementing Deep Learning models."
                }
            ]
        }
    })
</script>
<!-- Scripts -->
<script src="../assets/js/jquery.min.js"></script>
<script src="../assets/js/jquery.dropotron.min.js"></script>
<script src="../assets/js/browser.min.js"></script>
<script src="../assets/js/breakpoints.min.js"></script>
<script src="../assets/js/util.js"></script>
<script src="../assets/js/main.js"></script>
<script>
    $(document).ready(function () {


    });
</script>
</body>
</html>
